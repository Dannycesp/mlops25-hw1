{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Zoomcamp 2025 - Homework 1\n",
    "\n",
    "This notebook contains the solution for Homework 1 of the MLOps Zoomcamp 2025 course. The goal is to train a model for predicting taxi ride durations using Yellow Taxi Trip Records data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use the Yellow Taxi Trip Records for January and February 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured directory './data' exists.\n",
      "Downloading yellow_tripdata_2023-01.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet to ./data/yellow_tripdata_2023-01.parquet...\n",
      "--2025-05-09 23:28:42--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.160.226.85, 3.160.226.111, 3.160.226.161, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.160.226.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47673370 (45M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘./data/yellow_tripdata_2023-01.parquet’\n",
      "\n",
      "./data/yellow_tripd 100%[===================>]  45.46M  20.9MB/s    in 2.2s    \n",
      "\n",
      "2025-05-09 23:28:44 (20.9 MB/s) - ‘./data/yellow_tripdata_2023-01.parquet’ saved [47673370/47673370]\n",
      "\n",
      "Downloaded yellow_tripdata_2023-01.parquet.\n",
      "Downloaded files: {}\n",
      "Downloading yellow_tripdata_2023-02.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet to ./data/yellow_tripdata_2023-02.parquet...\n",
      "--2025-05-09 23:28:44--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.160.226.85, 3.160.226.228, 3.160.226.161, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.160.226.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47748012 (46M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘./data/yellow_tripdata_2023-02.parquet’\n",
      "\n",
      "./data/yellow_tripd 100%[===================>]  45.54M  22.6MB/s    in 2.0s    \n",
      "\n",
      "2025-05-09 23:28:46 (22.6 MB/s) - ‘./data/yellow_tripdata_2023-02.parquet’ saved [47748012/47748012]\n",
      "\n",
      "Downloaded yellow_tripdata_2023-02.parquet.\n",
      "Downloaded files: {}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define base URL and local download directory\n",
    "base_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/'\n",
    "download_dir = './data'\n",
    "\n",
    "# List of files to download specified by year-month\n",
    "# Add or remove entries here based on which months you need\n",
    "files_to_download = ['2023-01', '2023-02']\n",
    "\n",
    "# --- Download Files ---\n",
    "\n",
    "# Create the download directory if it doesn't exist\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "print(f\"Ensured directory '{download_dir}' exists.\")\n",
    "\n",
    "# Loop through the list and download each file if it doesn't exist\n",
    "downloaded_local_paths = {}\n",
    "\n",
    "for year_month in files_to_download:\n",
    "    # Construct the filename and full local path\n",
    "    file_name = f'yellow_tripdata_{year_month}.parquet'\n",
    "    local_file_path = os.path.join(download_dir, file_name)\n",
    "    file_url = f'{base_url}{file_name}'\n",
    "\n",
    "    # Check if the file already exists locally\n",
    "    if os.path.exists(local_file_path):\n",
    "        print(f\"File already exists: {local_file_path}. Skipping download.\")\n",
    "    else:\n",
    "        # If file does not exist, download it\n",
    "        print(f\"Downloading {file_name} from {file_url} to {local_file_path}...\")\n",
    "        # Use !wget command to download with output path specified\n",
    "        !wget {file_url} -O {local_file_path}\n",
    "        print(f\"Downloaded {file_name}.\")\n",
    "\n",
    "    # Store the local path for later loading\n",
    "    print(f\"Downloaded files: {downloaded_local_paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 dan dan 46M Mar 20  2023 data/yellow_tripdata_2023-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Check the file size and metadata\n",
    "\n",
    "!ls -lh data/yellow_tripdata_2023-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in January 2023 data: 19\n"
     ]
    }
   ],
   "source": [
    "# Load January data\n",
    "df_jan = pd.read_parquet('data/yellow_tripdata_2023-01.parquet')\n",
    "# Get the number of columns in the January DataFrame\n",
    "num_columns_jan = df_jan.shape[1]\n",
    "\n",
    "print(f\"Number of columns in January 2023 data: {num_columns_jan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Let's compute the duration variable and calculate its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(42.59435124195458)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load January data\n",
    "df_jan = pd.read_parquet('data/yellow_tripdata_2023-01.parquet')\n",
    "\n",
    "# Compute duration\n",
    "df_jan['duration'] = df_jan['tpep_dropoff_datetime'] - df_jan['tpep_pickup_datetime']\n",
    "df_jan['duration'] = df_jan['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# Calculate standard deviation\n",
    "std_duration = df_jan['duration'].std()\n",
    "std_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Let's remove records where duration is not between 1 and 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812202822125979"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out outliers\n",
    "df_filtered = df_jan[(df_jan['duration'] >= 1) & (df_jan['duration'] <= 60)]\n",
    "\n",
    "# Calculate fraction of remaining records\n",
    "fraction_remaining = len(df_filtered) / len(df_jan)\n",
    "fraction_remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's prepare the feature matrix using one-hot encoding for pickup and dropoff location IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61727/2015844691.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[categorical] = df_filtered[categorical].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3009173, 515)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df_filtered[categorical] = df_filtered[categorical].astype(str)\n",
    "\n",
    "# Convert to list of dictionaries\n",
    "train_dicts = df_filtered[categorical].to_dict(orient='records')\n",
    "\n",
    "# Create and fit DictVectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Get feature matrix dimensions\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Let's train a linear regression model and calculate the RMSE on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.649261936284003)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare target variable\n",
    "y_train = df_filtered['duration'].values\n",
    "\n",
    "# Train the model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "rmse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Let's evaluate the model on the validation data (February 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.811818654341152)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load February data\n",
    "df_feb = pd.read_parquet('data/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "# Compute duration\n",
    "df_feb['duration'] = df_feb['tpep_dropoff_datetime'] - df_feb['tpep_pickup_datetime']\n",
    "df_feb['duration'] = df_feb['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# Filter out outliers\n",
    "df_feb = df_feb[(df_feb['duration'] >= 1) & (df_feb['duration'] <= 60)]\n",
    "\n",
    "# Prepare validation data\n",
    "val_dicts = df_feb[categorical].astype(str).to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "y_val = df_feb['duration'].values\n",
    "\n",
    "# Make predictions\n",
    "y_pred_val = lr.predict(X_val)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "rmse_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_dataeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
